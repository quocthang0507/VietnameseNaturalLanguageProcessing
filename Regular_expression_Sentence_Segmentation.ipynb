{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regular expression - Sentence Segmentation",
      "provenance": [],
      "authorship_tag": "ABX9TyMiMyU8fCEOH4DlSVwXbVqk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quocthang0507/VietnameseNaturalLanguageProcessing/blob/main/Regular_expression_Sentence_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4KrKl1wZHf"
      },
      "source": [
        "# Solution 1\n",
        "https://stackoverflow.com/a/6755643"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKtTKmRkvFym",
        "outputId": "80e13cac-b0a2-4c97-c2a9-a34c67e6d66b"
      },
      "source": [
        "import re\n",
        "\n",
        "regx = re.compile('(?<![\\d.])(?!\\.\\.)'\n",
        "                  '(?<![\\d.][eE][+-])(?<![\\d.][eE])(?<!\\d[.,])'\n",
        "                  '' #---------------------------------\n",
        "                  '([+-]?)'\n",
        "                  '(?![\\d,]*?\\.[\\d,]*?\\.[\\d,]*?)'\n",
        "                  '(?:0|,(?=0)|(?<!\\d),)*'\n",
        "                  '(?:'\n",
        "                  '((?:\\d(?!\\.[1-9])|,(?=\\d))+)[.,]?'\n",
        "                  '|\\.(0)'\n",
        "                  '|((?<!\\.)\\.\\d+?)'\n",
        "                  '|([\\d,]+\\.\\d+?))'\n",
        "                  '0*'\n",
        "                  '' #---------------------------------\n",
        "                  '(?:'\n",
        "                  '([eE][+-]?)(?:0|,(?=0))*'\n",
        "                  '(?:'\n",
        "                  '(?!0+(?=\\D|\\Z))((?:\\d(?!\\.[1-9])|,(?=\\d))+)[.,]?'\n",
        "                  '|((?<!\\.)\\.(?!0+(?=\\D|\\Z))\\d+?)'\n",
        "                  '|([\\d,]+\\.(?!0+(?=\\D|\\Z))\\d+?))'\n",
        "                  '0*'\n",
        "                  ')?'\n",
        "                  '' #---------------------------------\n",
        "                  '(?![.,]?\\d)')\n",
        "\n",
        "simpler_regex = re.compile('(?<![\\d.])0*(?:'\n",
        "                           '(\\d+)\\.?|\\.(0)'\n",
        "                           '|(\\.\\d+?)|(\\d+\\.\\d+?)'\n",
        "                           ')0*(?![\\d.])')\n",
        "\n",
        "def split_outnumb(string, regx=regx, a=0):\n",
        "    excluded_pos = [x for mat in regx.finditer(string) for x in range(*mat.span()) if string[x]=='.']\n",
        "    li = []\n",
        "    for xdot in (x for x,c in enumerate(string) if c=='.' and x not in excluded_pos):\n",
        "        li.append(string[a:xdot])\n",
        "        a = xdot + 1\n",
        "    li.append(string[a:])\n",
        "    return li\n",
        "\n",
        "for sentence in ('hyper count 16.8mmol/l.plz review b4 5pm.just to inform u.thank u',\n",
        "                 'no of beds 8.please inform person in-charge.tq',\n",
        "                 'no of beds 8.2 cups of tea.tarabada',\n",
        "                 'this number .977 is a float',\n",
        "                 'numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific.notation',\n",
        "                 'an indian number 12,45,782.258 in this.sentence and 45,78,325. is another',\n",
        "                 'no dot in this sentence',\n",
        "                 ''):\n",
        "    print()\n",
        "    print('sentence = ', sentence)\n",
        "    print('splitted eyquem =', split_outnumb(sentence))\n",
        "    print('splitted eyqu 2 =', split_outnumb(sentence,regx=simpler_regex))\n",
        "    print('splitted gurney =', re.split(r\"\\.(?!\\d)\", sentence))\n",
        "    print('splitted stema =', re.split('(?<!\\d)\\.|\\.(?!\\d)',sentence))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sentence =  hyper count 16.8mmol/l.plz review b4 5pm.just to inform u.thank u\n",
            "splitted eyquem = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted eyqu 2 = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted gurney = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted stema = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "\n",
            "sentence =  no of beds 8.please inform person in-charge.tq\n",
            "splitted eyquem = ['no of beds 8.please inform person in-charge', 'tq']\n",
            "splitted eyqu 2 = ['no of beds 8.please inform person in-charge', 'tq']\n",
            "splitted gurney = ['no of beds 8', 'please inform person in-charge', 'tq']\n",
            "splitted stema = ['no of beds 8', 'please inform person in-charge', 'tq']\n",
            "\n",
            "sentence =  no of beds 8.2 cups of tea.tarabada\n",
            "splitted eyquem = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted eyqu 2 = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted gurney = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted stema = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "\n",
            "sentence =  this number .977 is a float\n",
            "splitted eyquem = ['this number .977 is a float']\n",
            "splitted eyqu 2 = ['this number .977 is a float']\n",
            "splitted gurney = ['this number .977 is a float']\n",
            "splitted stema = ['this number ', '977 is a float']\n",
            "\n",
            "sentence =  numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific.notation\n",
            "splitted eyquem = ['numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted eyqu 2 = ['numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted gurney = ['numbers 214.21E+45 , 478945', 'E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted stema = ['numbers 214.21E+45 , 478945', 'E-201 and ', '12478E+02 are in scientific', 'notation']\n",
            "\n",
            "sentence =  an indian number 12,45,782.258 in this.sentence and 45,78,325. is another\n",
            "splitted eyquem = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325. is another']\n",
            "splitted eyqu 2 = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325. is another']\n",
            "splitted gurney = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325', ' is another']\n",
            "splitted stema = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325', ' is another']\n",
            "\n",
            "sentence =  no dot in this sentence\n",
            "splitted eyquem = ['no dot in this sentence']\n",
            "splitted eyqu 2 = ['no dot in this sentence']\n",
            "splitted gurney = ['no dot in this sentence']\n",
            "splitted stema = ['no dot in this sentence']\n",
            "\n",
            "sentence =  \n",
            "splitted eyquem = ['']\n",
            "splitted eyqu 2 = ['']\n",
            "splitted gurney = ['']\n",
            "splitted stema = ['']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rXUAkCwxIQf"
      },
      "source": [
        "# Solution 2\n",
        "https://stackoverflow.com/a/25736082"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IIdqJvPxI7A",
        "outputId": "d02f0af5-f0c8-4d94-87b2-29b72fe3d877"
      },
      "source": [
        "regex_str = '(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s'\n",
        "text = \"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"\n",
        "tokens = re.split(regex_str, text)\n",
        "print('\\n'.join([sentence for sentence in tokens if sentence.strip() != '']))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
            "Did he mind?\n",
            "Adam Jones Jr. thinks he didn't.\n",
            "In any case, this isn't true...\n",
            "Well, with a probability of .9 it isn't.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VipwNScIy_bO"
      },
      "source": [
        "# Solution 3\n",
        "https://github.com/apoudel1021/Sentence-Segmentation/blob/master/sentencesegmentation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYfUP7X9zCQK"
      },
      "source": [
        "caps = \"([A-Z])\"\n",
        "digits = \"([0-9])\"\n",
        "lower = \"([a-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|MR|MRS)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "caps = \"([A-Z])\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](edu|com|net|org|io|gov)\"\n",
        "digits = \"([0-9])\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30yjCpSozKSG"
      },
      "source": [
        "def split_sentences(text):\n",
        "#    print text\n",
        "    text = \" \" + text + \"  \"\n",
        "#    print text\n",
        "    ''' Get the whole corpus removing all the new lines'''\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "#    print text\n",
        "    ''' Replace the dot on prefeixes with <use>  '''\n",
        "    text = re.sub(prefixes,\"\\\\1<use>\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "#    print text\n",
        "    ''' For the websites : Not really applicable for this project '''\n",
        "    text = re.sub(websites,\"<use>\\\\1\",text)\n",
        "    print(text)\n",
        "    ''' For Ph.D'''\n",
        "#    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<use> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    \n",
        "    '''A.B.C '''\n",
        "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<use>\\\\2<use>\\\\3<use>\",text)\n",
        "    '''  A.B  '''\n",
        "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    ''' a.b, e.g, i.e'''\n",
        "    text = re.sub(lower + \"[.]\" + lower + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    ''' i.e., e.g. '''\n",
        "    text = re.sub(lower + \"[.]\" + lower + \"[.]\"+ lower + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    \n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<use>\",text)\n",
        "    \n",
        "    ''' .A.'''\n",
        "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<use>\",text)\n",
        "    \n",
        "    '''checking for special cases like ...., ? , ! '''\n",
        "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<use>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = sentences[:-1]\n",
        "    i=1\n",
        "    \n",
        "    ''' writing output.txt'''\n",
        "    with open('output.txt','w') as text_file:\n",
        "        for s in sentences:\n",
        "            print(str(i) + ':' +s.strip())\n",
        "           \n",
        "            text_file.write(str(i) + ':' +s.strip()+\"\\n\")\n",
        "            i+=1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhuaIRp4zLfJ",
        "outputId": "af8c28b9-d6b5-466c-9e56-213b788587b8"
      },
      "source": [
        "split_sentences(text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mr<use> Smith bought cheapsite<use>com for 1<prd>5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.  \n",
            "1:Mr. Smith bought cheapsite.com for 1<prd>5 million dollars, i.e. he paid a lot for it.\n",
            "2:Did he mind?\n",
            "3:Adam Jones Jr. thinks he didn't.\n",
            "4:In any case, this isn't true<prd><prd><prd> Well, with a probability of .\n",
            "5:9 it isn't.\n"
          ]
        }
      ]
    }
  ]
}