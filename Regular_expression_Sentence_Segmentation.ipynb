{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regular expression - Sentence Segmentation",
      "provenance": [],
      "authorship_tag": "ABX9TyMC0u//87eM/uC8mbFqNrji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quocthang0507/VietnameseNaturalLanguageProcessing/blob/main/Regular_expression_Sentence_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWF2RbsPcBaY"
      },
      "source": [
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4KrKl1wZHf"
      },
      "source": [
        "# Solution 1\n",
        "https://stackoverflow.com/a/6755643"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKtTKmRkvFym",
        "outputId": "80e13cac-b0a2-4c97-c2a9-a34c67e6d66b"
      },
      "source": [
        "regx = re.compile('(?<![\\d.])(?!\\.\\.)'\n",
        "                  '(?<![\\d.][eE][+-])(?<![\\d.][eE])(?<!\\d[.,])'\n",
        "                  '' #---------------------------------\n",
        "                  '([+-]?)'\n",
        "                  '(?![\\d,]*?\\.[\\d,]*?\\.[\\d,]*?)'\n",
        "                  '(?:0|,(?=0)|(?<!\\d),)*'\n",
        "                  '(?:'\n",
        "                  '((?:\\d(?!\\.[1-9])|,(?=\\d))+)[.,]?'\n",
        "                  '|\\.(0)'\n",
        "                  '|((?<!\\.)\\.\\d+?)'\n",
        "                  '|([\\d,]+\\.\\d+?))'\n",
        "                  '0*'\n",
        "                  '' #---------------------------------\n",
        "                  '(?:'\n",
        "                  '([eE][+-]?)(?:0|,(?=0))*'\n",
        "                  '(?:'\n",
        "                  '(?!0+(?=\\D|\\Z))((?:\\d(?!\\.[1-9])|,(?=\\d))+)[.,]?'\n",
        "                  '|((?<!\\.)\\.(?!0+(?=\\D|\\Z))\\d+?)'\n",
        "                  '|([\\d,]+\\.(?!0+(?=\\D|\\Z))\\d+?))'\n",
        "                  '0*'\n",
        "                  ')?'\n",
        "                  '' #---------------------------------\n",
        "                  '(?![.,]?\\d)')\n",
        "\n",
        "simpler_regex = re.compile('(?<![\\d.])0*(?:'\n",
        "                           '(\\d+)\\.?|\\.(0)'\n",
        "                           '|(\\.\\d+?)|(\\d+\\.\\d+?)'\n",
        "                           ')0*(?![\\d.])')\n",
        "\n",
        "def split_outnumb(string, regx=regx, a=0):\n",
        "    excluded_pos = [x for mat in regx.finditer(string) for x in range(*mat.span()) if string[x]=='.']\n",
        "    li = []\n",
        "    for xdot in (x for x,c in enumerate(string) if c=='.' and x not in excluded_pos):\n",
        "        li.append(string[a:xdot])\n",
        "        a = xdot + 1\n",
        "    li.append(string[a:])\n",
        "    return li\n",
        "\n",
        "for sentence in ('hyper count 16.8mmol/l.plz review b4 5pm.just to inform u.thank u',\n",
        "                 'no of beds 8.please inform person in-charge.tq',\n",
        "                 'no of beds 8.2 cups of tea.tarabada',\n",
        "                 'this number .977 is a float',\n",
        "                 'numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific.notation',\n",
        "                 'an indian number 12,45,782.258 in this.sentence and 45,78,325. is another',\n",
        "                 'no dot in this sentence',\n",
        "                 ''):\n",
        "    print()\n",
        "    print('sentence = ', sentence)\n",
        "    print('splitted eyquem =', split_outnumb(sentence))\n",
        "    print('splitted eyqu 2 =', split_outnumb(sentence,regx=simpler_regex))\n",
        "    print('splitted gurney =', re.split(r\"\\.(?!\\d)\", sentence))\n",
        "    print('splitted stema =', re.split('(?<!\\d)\\.|\\.(?!\\d)',sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sentence =  hyper count 16.8mmol/l.plz review b4 5pm.just to inform u.thank u\n",
            "splitted eyquem = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted eyqu 2 = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted gurney = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "splitted stema = ['hyper count 16.8mmol/l', 'plz review b4 5pm', 'just to inform u', 'thank u']\n",
            "\n",
            "sentence =  no of beds 8.please inform person in-charge.tq\n",
            "splitted eyquem = ['no of beds 8.please inform person in-charge', 'tq']\n",
            "splitted eyqu 2 = ['no of beds 8.please inform person in-charge', 'tq']\n",
            "splitted gurney = ['no of beds 8', 'please inform person in-charge', 'tq']\n",
            "splitted stema = ['no of beds 8', 'please inform person in-charge', 'tq']\n",
            "\n",
            "sentence =  no of beds 8.2 cups of tea.tarabada\n",
            "splitted eyquem = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted eyqu 2 = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted gurney = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "splitted stema = ['no of beds 8.2 cups of tea', 'tarabada']\n",
            "\n",
            "sentence =  this number .977 is a float\n",
            "splitted eyquem = ['this number .977 is a float']\n",
            "splitted eyqu 2 = ['this number .977 is a float']\n",
            "splitted gurney = ['this number .977 is a float']\n",
            "splitted stema = ['this number ', '977 is a float']\n",
            "\n",
            "sentence =  numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific.notation\n",
            "splitted eyquem = ['numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted eyqu 2 = ['numbers 214.21E+45 , 478945.E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted gurney = ['numbers 214.21E+45 , 478945', 'E-201 and .12478E+02 are in scientific', 'notation']\n",
            "splitted stema = ['numbers 214.21E+45 , 478945', 'E-201 and ', '12478E+02 are in scientific', 'notation']\n",
            "\n",
            "sentence =  an indian number 12,45,782.258 in this.sentence and 45,78,325. is another\n",
            "splitted eyquem = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325. is another']\n",
            "splitted eyqu 2 = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325. is another']\n",
            "splitted gurney = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325', ' is another']\n",
            "splitted stema = ['an indian number 12,45,782.258 in this', 'sentence and 45,78,325', ' is another']\n",
            "\n",
            "sentence =  no dot in this sentence\n",
            "splitted eyquem = ['no dot in this sentence']\n",
            "splitted eyqu 2 = ['no dot in this sentence']\n",
            "splitted gurney = ['no dot in this sentence']\n",
            "splitted stema = ['no dot in this sentence']\n",
            "\n",
            "sentence =  \n",
            "splitted eyquem = ['']\n",
            "splitted eyqu 2 = ['']\n",
            "splitted gurney = ['']\n",
            "splitted stema = ['']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rXUAkCwxIQf"
      },
      "source": [
        "# Solution 2\n",
        "https://stackoverflow.com/a/25736082"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IIdqJvPxI7A",
        "outputId": "d02f0af5-f0c8-4d94-87b2-29b72fe3d877"
      },
      "source": [
        "regex_str = '(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s'\n",
        "text = \"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"\n",
        "tokens = re.split(regex_str, text)\n",
        "print('\\n'.join([sentence for sentence in tokens if sentence.strip() != '']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
            "Did he mind?\n",
            "Adam Jones Jr. thinks he didn't.\n",
            "In any case, this isn't true...\n",
            "Well, with a probability of .9 it isn't.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3q5M42ub4uc"
      },
      "source": [
        "def split_text_to_sentences_by_regex(text, regex=r'(?<!\\w\\.\\w|\\w\\!\\w|\\w\\?\\w)(?<=\\.|\\?|\\!)\\s'):\n",
        "    '''Tách đoạn văn thành các câu bằng regex'''\n",
        "    if not text or not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.replace('\\n', '. ')\n",
        "    tokens = re.split(regex, text)\n",
        "    return [sentence for sentence in tokens if sentence.strip() != '']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYCgPghzcLkH"
      },
      "source": [
        "sent_1 = ['Dù đã hơn 80 tuổi nhưng những lúc rảnh rỗi, già làng A Nguyh vẫn thường xuyên đến từng hộ gia đình để tuyên truyền chủ trương của Đảng, chính sách, pháp luật của Nhà nước, vận động đồng bào tích cực ứng dụng khoa học - kỹ thuật vào sản xuất, giữ gìn vệ sinh thôn, bản, loại bỏ dần những hủ tục lạc hậu... Già làng A Nguyh còn là người đầu tiên trong thôn Kép Ram biết trồng lúa 2 vụ, biết trồng các loại cây công nghiệp như cao su, bời lời... Đến nay, gia đình già đã có 1 ha cà phê, 1 ha bời lời, 1 ha mía, 1 ha cao su và 6 sào lúa, mỗi năm thu về hơn 100 triệu đồng. Già A Nguyh cũng thường xuyên hướng dẫn đồng bào trong thôn kinh nghiệm sản xuất, từ đó cải thiện đời sống gia đình.',\n",
        "\"Bŭ lah neh rơlau 80 sơnăm mơya ală tŭ ru lơngà, kra ƀòn A Nguyh gam ờs sùm tus dơ hìu bơnhă làng yal tơng git rơndăp tăp sèng Đảng, tơng gume, gơnoăt Dà lơgar dê, boh lam làng bol lơh ngăn đòm jăt bơta git wă - lơh chài tam tơlik broă lơh, sền gàr goh niam ƀòn, ròt ơm, sang sơbì rơhời ală bơhiàn yau ờ gơ - dờp tai... Kra ƀòn A Nguyh gam lah cau sơnrờp tam ƀòn Kép Ram git tăm kòi 2 kàl, git tăm ală bơta tờm chi jŏ tơngai bè cao su, bời lời... Tus tŭ do, hìu bơnhă kra neh geh 1 lồ kơ phe, 1 lồ bời lời, 1 lồ tào, 1 lồ cao su mơ 6 sào kòi, pah năm lơh gơlik geh rơlau 100 tơlăk priă. Kra A Nguyh krung ờs sùm lam sơnđio làng bol tam ƀòn bơta git lơh chài tơlik broă lơh, bơh n'hơ\\ lơh guh pơniam rài kis hìu bơnhă.\"]\n",
        "sent_2 = ['Ngày nay, sự hòa đồng về lối sống, ảnh hưởng qua lại về phong tục, tập quán... khiến nhiều nét văn hóa cổ truyền đang bị mai một. Chính vì vậy, rất cần gìn giữ, bảo tồn và phát huy các giá trị văn hóa, trong đó có biểu tượng \"Khau cút\" của người Thái đen vùng Tây Bắc.',\n",
        "'Ngai do, bơta lơh ring ròi nùs nhơm jăt wèt sơnah kis, lơh gơtus wil war jăt bơhiàn, broă lơh ờs mờng... lơh gơtus geh niam is adăt chài rơgơi yau lam gam geh lơh roh rui. Bơh tờm bè hơ\\, kờñ ngăn sền prăp, griap gàr mơ lơh pơnjăt guh ală yòm màng adăt chài rơgơi, tam hơ\\ geh rùp lơh gŏ \"Khau cút\" cau Thái jù tiah Tây Bắc dê.']\n",
        "sent_3 = ['Theo Phòng Nông nghiệp và Phát triển nông thôn huyện Lục Ngạn, toàn huyện hiện có trên 15.000 ha vải, hầu hết được chăm sóc theo quy trình VietGAP và GlobalGAP; sản lượng vụ vải năm nay ước đạt 85.000 tấn, trong đó vải chín sớm khoảng 20.000 tấn, vải chính vụ 65.000 - 67.000 tấn. So với quả vải ở những địa phương khác, vải thiều Lục Ngạn khi chín có màu đỏ, vỏ mỏng, hạt nhỏ, cùi dày, vị ngọt đậm, giàu chất dinh dưỡng... khiến người ăn cứ muốn thưởng thức thêm và mua thật nhiều để làm quà cho gia đình và người thân.',\n",
        "'Jăt Sơnah lơh broă Tăm tùc mơ Tơng guh ƀòn ơm kơnhuàl Lục Ngạn, tam kơnhuàl tŭ do geh hơđang 15.000 vải, yơu bè jơh geh sơng ka jăt broă tơlik lơh VietGAP mơ GlobalGAP; kờp trơgòm geh oă kàl plai vải năm do pơgăp 85.000 tấn, tam hơ\\ plai vải dum gờñ dikàr 20.000 tấn, plai vải thiều lơh dikàl 65.000 - 67.000 tấn. Di pơndrờm mơ plai vải thiều hơ anih ơm ndai, plai vải Lục Ngạn tŭ dum geh gur prơhê, kơmhò lơhơ, gar dêt, să lơ - ut (mbơl), sa lơngồt, oă bơta bơkah lơnga... lơh cau sa in sùm kờñ sa tai mơ blơi oă ngăn làng lơh phan pà hìu bơnhă mơ cau kuèng in.']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDDfTqXcOQG"
      },
      "source": [
        "def print_array(arr):\n",
        "    i = 0\n",
        "    for s in arr:\n",
        "        for ss in s:\n",
        "            print(f'{i+1}. {ss}')\n",
        "            i += 1\n",
        "        print()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1xFHVHscRC1"
      },
      "source": [
        "def arr_tokenizer(text_arr: list):\n",
        "    return [split_text_to_sentences_by_regex(item) for item in text_arr]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1meatMZcWSh",
        "outputId": "83a1bd91-47f4-47ab-e571-212ecdc6a920"
      },
      "source": [
        "print_array(arr_tokenizer(sent_1))\n",
        "print_array(arr_tokenizer(sent_2))\n",
        "print_array(arr_tokenizer(sent_3))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Dù đã hơn 80 tuổi nhưng những lúc rảnh rỗi, già làng A Nguyh vẫn thường xuyên đến từng hộ gia đình để tuyên truyền chủ trương của Đảng, chính sách, pháp luật của Nhà nước, vận động đồng bào tích cực ứng dụng khoa học - kỹ thuật vào sản xuất, giữ gìn vệ sinh thôn, bản, loại bỏ dần những hủ tục lạc hậu...\n",
            "2. Già làng A Nguyh còn là người đầu tiên trong thôn Kép Ram biết trồng lúa 2 vụ, biết trồng các loại cây công nghiệp như cao su, bời lời...\n",
            "3. Đến nay, gia đình già đã có 1 ha cà phê, 1 ha bời lời, 1 ha mía, 1 ha cao su và 6 sào lúa, mỗi năm thu về hơn 100 triệu đồng.\n",
            "4. Già A Nguyh cũng thường xuyên hướng dẫn đồng bào trong thôn kinh nghiệm sản xuất, từ đó cải thiện đời sống gia đình.\n",
            "\n",
            "5. Bŭ lah neh rơlau 80 sơnăm mơya ală tŭ ru lơngà, kra ƀòn A Nguyh gam ờs sùm tus dơ hìu bơnhă làng yal tơng git rơndăp tăp sèng Đảng, tơng gume, gơnoăt Dà lơgar dê, boh lam làng bol lơh ngăn đòm jăt bơta git wă - lơh chài tam tơlik broă lơh, sền gàr goh niam ƀòn, ròt ơm, sang sơbì rơhời ală bơhiàn yau ờ gơ - dờp tai...\n",
            "6. Kra ƀòn A Nguyh gam lah cau sơnrờp tam ƀòn Kép Ram git tăm kòi 2 kàl, git tăm ală bơta tờm chi jŏ tơngai bè cao su, bời lời...\n",
            "7. Tus tŭ do, hìu bơnhă kra neh geh 1 lồ kơ phe, 1 lồ bời lời, 1 lồ tào, 1 lồ cao su mơ 6 sào kòi, pah năm lơh gơlik geh rơlau 100 tơlăk priă.\n",
            "8. Kra A Nguyh krung ờs sùm lam sơnđio làng bol tam ƀòn bơta git lơh chài tơlik broă lơh, bơh n'hơ\\ lơh guh pơniam rài kis hìu bơnhă.\n",
            "\n",
            "1. Ngày nay, sự hòa đồng về lối sống, ảnh hưởng qua lại về phong tục, tập quán...\n",
            "2. khiến nhiều nét văn hóa cổ truyền đang bị mai một.\n",
            "3. Chính vì vậy, rất cần gìn giữ, bảo tồn và phát huy các giá trị văn hóa, trong đó có biểu tượng \"Khau cút\" của người Thái đen vùng Tây Bắc.\n",
            "\n",
            "4. Ngai do, bơta lơh ring ròi nùs nhơm jăt wèt sơnah kis, lơh gơtus wil war jăt bơhiàn, broă lơh ờs mờng...\n",
            "5. lơh gơtus geh niam is adăt chài rơgơi yau lam gam geh lơh roh rui.\n",
            "6. Bơh tờm bè hơ\\, kờñ ngăn sền prăp, griap gàr mơ lơh pơnjăt guh ală yòm màng adăt chài rơgơi, tam hơ\\ geh rùp lơh gŏ \"Khau cút\" cau Thái jù tiah Tây Bắc dê.\n",
            "\n",
            "1. Theo Phòng Nông nghiệp và Phát triển nông thôn huyện Lục Ngạn, toàn huyện hiện có trên 15.000 ha vải, hầu hết được chăm sóc theo quy trình VietGAP và GlobalGAP; sản lượng vụ vải năm nay ước đạt 85.000 tấn, trong đó vải chín sớm khoảng 20.000 tấn, vải chính vụ 65.000 - 67.000 tấn.\n",
            "2. So với quả vải ở những địa phương khác, vải thiều Lục Ngạn khi chín có màu đỏ, vỏ mỏng, hạt nhỏ, cùi dày, vị ngọt đậm, giàu chất dinh dưỡng...\n",
            "3. khiến người ăn cứ muốn thưởng thức thêm và mua thật nhiều để làm quà cho gia đình và người thân.\n",
            "\n",
            "4. Jăt Sơnah lơh broă Tăm tùc mơ Tơng guh ƀòn ơm kơnhuàl Lục Ngạn, tam kơnhuàl tŭ do geh hơđang 15.000 vải, yơu bè jơh geh sơng ka jăt broă tơlik lơh VietGAP mơ GlobalGAP; kờp trơgòm geh oă kàl plai vải năm do pơgăp 85.000 tấn, tam hơ\\ plai vải dum gờñ dikàr 20.000 tấn, plai vải thiều lơh dikàl 65.000 - 67.000 tấn.\n",
            "5. Di pơndrờm mơ plai vải thiều hơ anih ơm ndai, plai vải Lục Ngạn tŭ dum geh gur prơhê, kơmhò lơhơ, gar dêt, să lơ - ut (mbơl), sa lơngồt, oă bơta bơkah lơnga...\n",
            "6. lơh cau sa in sùm kờñ sa tai mơ blơi oă ngăn làng lơh phan pà hìu bơnhă mơ cau kuèng in.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VipwNScIy_bO"
      },
      "source": [
        "# Solution 3\n",
        "https://github.com/apoudel1021/Sentence-Segmentation/blob/master/sentencesegmentation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYfUP7X9zCQK"
      },
      "source": [
        "caps = \"([A-Z])\"\n",
        "digits = \"([0-9])\"\n",
        "lower = \"([a-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr|MR|MRS)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "caps = \"([A-Z])\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](edu|com|net|org|io|gov)\"\n",
        "digits = \"([0-9])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30yjCpSozKSG"
      },
      "source": [
        "def split_sentences(text):\n",
        "#    print text\n",
        "    text = \" \" + text + \"  \"\n",
        "#    print text\n",
        "    ''' Get the whole corpus removing all the new lines'''\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "#    print text\n",
        "    ''' Replace the dot on prefeixes with <use>  '''\n",
        "    text = re.sub(prefixes,\"\\\\1<use>\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "#    print text\n",
        "    ''' For the websites : Not really applicable for this project '''\n",
        "    text = re.sub(websites,\"<use>\\\\1\",text)\n",
        "    print(text)\n",
        "    ''' For Ph.D'''\n",
        "#    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<use> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    \n",
        "    '''A.B.C '''\n",
        "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<use>\\\\2<use>\\\\3<use>\",text)\n",
        "    '''  A.B  '''\n",
        "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    ''' a.b, e.g, i.e'''\n",
        "    text = re.sub(lower + \"[.]\" + lower + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    ''' i.e., e.g. '''\n",
        "    text = re.sub(lower + \"[.]\" + lower + \"[.]\"+ lower + \"[.]\",\"\\\\1<use>\\\\2<use>\",text)\n",
        "    \n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<use>\",text)\n",
        "    \n",
        "    ''' .A.'''\n",
        "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<use>\",text)\n",
        "    \n",
        "    '''checking for special cases like ...., ? , ! '''\n",
        "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<use>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = sentences[:-1]\n",
        "    i=1\n",
        "    \n",
        "    ''' writing output.txt'''\n",
        "    with open('output.txt','w') as text_file:\n",
        "        for s in sentences:\n",
        "            print(str(i) + ':' +s.strip())\n",
        "           \n",
        "            text_file.write(str(i) + ':' +s.strip()+\"\\n\")\n",
        "            i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhuaIRp4zLfJ",
        "outputId": "af8c28b9-d6b5-466c-9e56-213b788587b8"
      },
      "source": [
        "split_sentences(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mr<use> Smith bought cheapsite<use>com for 1<prd>5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.  \n",
            "1:Mr. Smith bought cheapsite.com for 1<prd>5 million dollars, i.e. he paid a lot for it.\n",
            "2:Did he mind?\n",
            "3:Adam Jones Jr. thinks he didn't.\n",
            "4:In any case, this isn't true<prd><prd><prd> Well, with a probability of .\n",
            "5:9 it isn't.\n"
          ]
        }
      ]
    }
  ]
}