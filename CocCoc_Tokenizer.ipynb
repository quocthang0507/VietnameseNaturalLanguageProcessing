{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CocCoc Tokenizer",
      "provenance": [],
      "authorship_tag": "ABX9TyOJJMXEmhcTILqZpOnMDR/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quocthang0507/VietnameseNaturalLanguageProcessing/blob/main/CocCoc_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIiKhh-hKcFQ",
        "outputId": "ce3b8daf-9f68-4937-cb42-541a3b6e119f"
      },
      "source": [
        "!git clone https://github.com/coccoc/coccoc-tokenizer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'coccoc-tokenizer'...\n",
            "remote: Enumerating objects: 342, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 342 (delta 0), reused 2 (delta 0), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (342/342), 55.95 MiB | 27.13 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0OYxUEPOjgK",
        "outputId": "349b024d-ccf9-4990-a869-540a9eebf5f4"
      },
      "source": [
        "%cd coccoc-tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/coccoc-tokenizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEIdh3OaOs4T"
      },
      "source": [
        "!mkdir build"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6IA14PKOyPP",
        "outputId": "cc29704d-c9bf-4d01-b816-6614ecf5cff9"
      },
      "source": [
        "%cd build"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/coccoc-tokenizer/build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLzKY3j-PGvN",
        "outputId": "8b7cd621-486b-4442-87a5-8b2766728f35"
      },
      "source": [
        "!cmake -DBUILD_JAVA=1 -DBUILD_PYTHON=1 -DCMAKE_INSTALL_PREFIX=~/.local .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/coccoc-tokenizer/build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isk_3zWgPKEL",
        "outputId": "9d5bb82c-f062-483a-e026-c58f574aad8b"
      },
      "source": [
        "!make install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[35m\u001b[1mScanning dependencies of target dict_compiler\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/dict_compiler.dir/utils/dict_compiler.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32m\u001b[1mLinking CXX executable dict_compiler\u001b[0m\n",
            "[ 22%] Built target dict_compiler\n",
            "\u001b[35m\u001b[1mScanning dependencies of target tokenizer\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/tokenizer.dir/utils/tokenizer.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32m\u001b[1mLinking CXX executable tokenizer\u001b[0m\n",
            "[ 44%] Built target tokenizer\n",
            "\u001b[35m\u001b[1mScanning dependencies of target vn_lang_tool\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/vn_lang_tool.dir/utils/vn_lang_tool.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32m\u001b[1mLinking CXX executable vn_lang_tool\u001b[0m\n",
            "[ 66%] Built target vn_lang_tool\n",
            "\u001b[35m\u001b[1mScanning dependencies of target compile_dict\u001b[0m\n",
            "[ 77%] \u001b[34m\u001b[1mGenerating multiterm_trie.dump, syllable_trie.dump, nontone_pair_freq_map.dump\u001b[0m\n",
            "[ 77%] Built target compile_dict\n",
            "\u001b[35m\u001b[1mScanning dependencies of target compile_java\u001b[0m\n",
            "[ 88%] \u001b[34m\u001b[1mGenerating coccoc-tokenizer.jar\u001b[0m\n",
            "../java/src/java/Unsafe.java:7: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\tpublic static final sun.misc.Unsafe UNSAFE;\n",
            "\t                            ^\n",
            "../java/src/java/Unsafe.java:10: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tsun.misc.Unsafe unsafe = null;\n",
            "\t\t        ^\n",
            "../java/src/java/Unsafe.java:12: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\t\tField field = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\n",
            "\t\t\t                      ^\n",
            "../java/src/java/Unsafe.java:14: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\t\tunsafe = (sun.misc.Unsafe) field.get(null);\n",
            "\t\t\t                  ^\n",
            "../java/src/java/Unsafe.java:42: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getFloat(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                               ^\n",
            "../java/src/java/Unsafe.java:46: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getDouble(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                                ^\n",
            "../java/src/java/Unsafe.java:50: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getLong(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                              ^\n",
            "../java/src/java/Unsafe.java:54: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getInt(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                             ^\n",
            "../java/src/java/Unsafe.java:58: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getShort(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                               ^\n",
            "../java/src/java/Unsafe.java:62: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\treturn UNSAFE.getByte(buffer, (long) (sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + offset));\n",
            "\t\t                                              ^\n",
            "../java/src/java/Unsafe.java:91: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tUNSAFE.copyMemory(values, sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET, null, pointer, length);\n",
            "\t\t                                  ^\n",
            "../java/src/java/Unsafe.java:95: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tUNSAFE.copyMemory(values, sun.misc.Unsafe.ARRAY_BYTE_BASE_OFFSET + off, null, pointer, length);\n",
            "\t\t                                  ^\n",
            "../java/src/java/Unsafe.java:99: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tUNSAFE.copyMemory(values, sun.misc.Unsafe.ARRAY_SHORT_BASE_OFFSET, null, pointer, length * Short.BYTES);\n",
            "\t\t                                  ^\n",
            "../java/src/java/Unsafe.java:103: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tUNSAFE.copyMemory(values, sun.misc.Unsafe.ARRAY_INT_BASE_OFFSET, null, pointer, length * Integer.BYTES);\n",
            "\t\t                                  ^\n",
            "../java/src/java/Unsafe.java:107: warning: Unsafe is internal proprietary API and may be removed in a future release\n",
            "\t\tUNSAFE.copyMemory(values, sun.misc.Unsafe.ARRAY_LONG_BASE_OFFSET, null, pointer, length * Long.BYTES);\n",
            "\t\t                                  ^\n",
            "15 warnings\n",
            "[ 88%] Built target compile_java\n",
            "\u001b[35m\u001b[1mScanning dependencies of target compile_python\u001b[0m\n",
            "[100%] \u001b[34m\u001b[1mGenerating python/lib\u001b[0m\n",
            "running install\n",
            "running build\n",
            "running build_ext\n",
            "cythoning CocCocTokenizer.pyx to CocCocTokenizer.cpp\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/coccoc-tokenizer/python/CocCocTokenizer.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'CocCocTokenizer' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -I.. -I/content/coccoc-tokenizer/build/auto -O2 -march=native -Wno-cpp -Wno-unused-function -std=c++11 -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -c CocCocTokenizer.cpp -o build/temp.linux-x86_64-3.7/CocCocTokenizer.o\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -I.. -I/content/coccoc-tokenizer/build/auto -O2 -march=native -Wno-cpp -Wno-unused-function -std=c++11 -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/CocCocTokenizer.o -o build/lib.linux-x86_64-3.7/CocCocTokenizer.cpython-37m-x86_64-linux-gnu.so\n",
            "running install_lib\n",
            "creating /content/coccoc-tokenizer/build/python\n",
            "creating /content/coccoc-tokenizer/build/python/lib\n",
            "creating /content/coccoc-tokenizer/build/python/lib/python3.7\n",
            "creating /content/coccoc-tokenizer/build/python/lib/python3.7/site-packages\n",
            "copying build/lib.linux-x86_64-3.7/CocCocTokenizer.cpython-37m-x86_64-linux-gnu.so -> /content/coccoc-tokenizer/build/python/lib/python3.7/site-packages\n",
            "running install_egg_info\n",
            "Writing /content/coccoc-tokenizer/build/python/lib/python3.7/site-packages/CocCocTokenizer-1.4-py3.7.egg-info\n",
            "[100%] Built target compile_python\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"RELEASE\"\n",
            "-- Installing: /root/.local/bin/tokenizer\n",
            "-- Installing: /root/.local/bin/vn_lang_tool\n",
            "-- Installing: /root/.local/bin/dict_compiler\n",
            "-- Installing: /root/.local/include/tokenizer\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/utf8\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/utf8/checked.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/utf8/core.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/utf8/unchecked.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/tsl\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/tsl/robin_hash.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/tsl/robin_set.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/tsl/robin_map.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/tsl/robin_growth_policy.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/utf8.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_timer.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_smartptr.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_utils.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_stdint.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_memory.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_config.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_dlalloc.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp_traits.h\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/sparsepp/spp.h\n",
            "-- Up-to-date: /root/.local/include/tokenizer\n",
            "-- Installing: /root/.local/include/tokenizer/helper.hpp\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/utf8\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie.hpp\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/tsl\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/vn_lang_tool.hpp\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/trie\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/da_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/syllable_hash_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/multiterm_da_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/syllable_hash_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/string_set_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/multiterm_hash_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/da_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/syllable_da_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/multiterm_da_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/multiterm_hash_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/syllable_da_trie.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/hash_trie_node.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/trie/hash_trie.hpp\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/sparsepp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/buffered_reader.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/auxiliary/file_serializer.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/tokenizer.hpp\n",
            "-- Installing: /root/.local/include/tokenizer/token.hpp\n",
            "-- Up-to-date: /root/.local/include/tokenizer\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/utf8\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/tsl\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/trie\n",
            "-- Up-to-date: /root/.local/include/tokenizer/auxiliary/sparsepp\n",
            "-- Installing: /root/.local/include/tokenizer/config.h\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/nontone_pair_freq\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/chemical_comp\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/vndic_multiterm\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/acronyms\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/special_token.weak\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/Freq2NontoneUniFile\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/special_token.strong\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/tokenizer/keyword.freq\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/vn_lang_tool\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/vn_lang_tool/alphabetic\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/vn_lang_tool/d_and_gi.txt\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/vn_lang_tool/i_and_y.txt\n",
            "-- Installing: /root/.local/share/tokenizer/dicts_text/vn_lang_tool/numeric\n",
            "-- Installing: /root/.local/share/tokenizer/dicts\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/alphabetic\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/d_and_gi.txt\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/i_and_y.txt\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/numeric\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/multiterm_trie.dump\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/syllable_trie.dump\n",
            "-- Installing: /root/.local/share/tokenizer/dicts/nontone_pair_freq_map.dump\n",
            "-- Installing: /root/.local/share/java/coccoc-tokenizer.jar\n",
            "-- Installing: /root/.local/lib/libcoccoc_tokenizer_jni.so\n",
            "-- Up-to-date: /root/.local/lib\n",
            "-- Installing: /root/.local/lib/python3.7\n",
            "-- Installing: /root/.local/lib/python3.7/site-packages\n",
            "-- Installing: /root/.local/lib/python3.7/site-packages/CocCocTokenizer.cpython-37m-x86_64-linux-gnu.so\n",
            "-- Installing: /root/.local/lib/python3.7/site-packages/CocCocTokenizer-1.4-py3.7.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye3GIsYuVhv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc8e3db-90e4-404d-987f-0b61988cec07"
      },
      "source": [
        "!tokenizer \"Từng bước để trở thành một lập trình viên giỏi\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: tokenizer: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "1iVssAPpU0pJ",
        "outputId": "6edecb1e-6874-4910-b01a-f4bede3bab13"
      },
      "source": [
        "from CocCocTokenizer import PyTokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e9caafca0f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCocCocTokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CocCocTokenizer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}